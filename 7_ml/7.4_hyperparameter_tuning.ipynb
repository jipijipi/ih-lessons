{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In our pursuit of optimizing predictive performance for California housing price prediction, we turn our attention towards hyperparameter tuning. \n",
        "\n",
        "Hyperparameters play a pivotal role in shaping the behavior and performance of machine learning models, and fine-tuning them can lead to significant improvements in predictive accuracy and generalization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Loading and preparing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "EtaTRaHofi4G"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import  fetch_california_housing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor,AdaBoostRegressor, GradientBoostingRegressor\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2yWTS79ILEB"
      },
      "outputs": [],
      "source": [
        "california = fetch_california_housing()\n",
        "print(california[\"DESCR\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-5p1yj1fuxU",
        "outputId": "6c1905bb-4c3f-4f4b-8893-e899a889b154"
      },
      "outputs": [],
      "source": [
        "df_cali = pd.DataFrame(california[\"data\"], columns = california[\"feature_names\"])\n",
        "df_cali[\"median_house_value\"] = california[\"target\"]\n",
        "\n",
        "df_cali.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Normalization & Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Like we did in Feature Engineering lesson, we are going to normalize our data and select a subset of columns as our features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = df_cali.drop(columns = [\"median_house_value\",\"AveOccup\", \"Population\", \"AveBedrms\"])\n",
        "target = df_cali[\"median_house_value\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.20, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create an instance of the normalizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "normalizer = MinMaxScaler()\n",
        "\n",
        "normalizer.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_norm = normalizer.transform(X_train)\n",
        "\n",
        "X_test_norm = normalizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_norm = pd.DataFrame(X_train_norm, columns = X_train.columns)\n",
        "X_test_norm = pd.DataFrame(X_test_norm, columns = X_test.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccJlogiXJHH_"
      },
      "source": [
        "# Grid Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Grid Search** - we define a grid of hyperparameter values we want to try. Grid Search tries all possible combinations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So far, our best model was AdaBoost yield a R-Squared of 0.83.\n",
        "\n",
        "\n",
        "Let's see how we fine tune our model, in order to that, we will optimize the following hyperparameters:\n",
        "\n",
        "- **n_estimators:** number of estimators, in this case, number of trees\n",
        "\n",
        "- **max_leaf_nodes:** maxium number of total leafs to consider\n",
        "\n",
        "- **max_depth:** maxium number of levels in each tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- First we define the grid with values to consider when train all possible combinations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFNFsVZ9Q0fD",
        "outputId": "9f57e6d3-2b1e-4859-f091-00815b042700"
      },
      "outputs": [],
      "source": [
        "grid = {\"n_estimators\": [50, 100, 200,500],\n",
        "        \"estimator__max_leaf_nodes\": [250, 500, 1000, None],\n",
        "        \"estimator__max_depth\":[10,30,50]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "ada_reg = AdaBoostRegressor(DecisionTreeRegressor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = GridSearchCV(estimator = ada_reg, param_grid = grid, cv=5, n_jobs=-1, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(X_train_norm, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- After training, we check what are the best values for the hyperparameters that we have tested."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- You can retrieve the best model with the best parameters when accessing **best_estimator_** attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = model.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Evaluate our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lJh1N0rjCZZ"
      },
      "outputs": [],
      "source": [
        "pred = best_model.predict(X_test_norm)\n",
        "\n",
        "print(\"MAE\", mean_absolute_error(pred, y_test))\n",
        "print(\"RMSE\", mean_squared_error(pred, y_test, squared=False))\n",
        "print(\"R2 score\", best_model.score(X_test_norm, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuaARRUULs5i"
      },
      "source": [
        "# Random Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Random Search** - we define probability distributions for each hyperparameter, from which random values are sampled. Itâ€™s up to the researcher to set the maximum number of combinations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "ZtTCOs5wnf1X"
      },
      "outputs": [],
      "source": [
        "grid = {\"n_estimators\": [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)],\n",
        "        \"estimator__max_leaf_nodes\": [int(x) for x in np.linspace(start = 500, stop = 3000, num = 10)],\n",
        "        \"estimator__max_depth\":[int(x) for x in np.linspace(10, 110, num = 11)]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "7MYPEoocmd2b"
      },
      "outputs": [],
      "source": [
        "ada_reg = AdaBoostRegressor(DecisionTreeRegressor())\n",
        "\n",
        "model = RandomizedSearchCV(estimator = ada_reg, param_distributions = grid, n_iter = 10, cv = 5, n_jobs = -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "8Y2VVxJXnnST",
        "outputId": "7cfabbb2-6983-4709-9421-55a7917845c3"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train_norm,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGdVa9ojO0Dr",
        "outputId": "92bb9292-4abe-47b0-e859-0bb3cc0d27cb"
      },
      "outputs": [],
      "source": [
        "model.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- You can retrieve the best model with the best parameters when accessing **best_estimator_** attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = model.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Evaluate our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred = best_model.predict(X_test_norm)\n",
        "\n",
        "print(\"MAE\", mean_absolute_error(pred, y_test))\n",
        "print(\"RMSE\", mean_squared_error(pred, y_test, squared=False))\n",
        "print(\"R2 score\", best_model.score(X_test_norm, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We dont guarantee these hyperparameters are optimal! We can just guarantee that these are the best from the ones we tried!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
